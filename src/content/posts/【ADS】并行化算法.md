---
title: 【ADS】并行化算法
published: 2024-12-16
description: ''
image: ''
tags: [notes]
category: 'ADS'
draft: false 
lang: ''
---
# 并行算法公式和结论

<!-- toc -->



## 1. 并行随机访问机（PRAM）模型
### 1.1 模型基础
- **单位时间操作**：  
  读、写、计算均为单位时间完成。

- **多处理器并发模型**：  
  - 共享内存架构，处理器通过**独占读/写**或**并发读/写**访问内存。

---

## 2. 工作-深度（Work-Depth）模型
### 2.1 公式定义
- 总工作量：  
  $W = \text{树中所有节点的总数}$

- 深度：  
  $D = \text{树的高度}$

- 并行运行时间（P个处理器）：  
  $$T = O\left(\frac{W}{P} + D\right)$$

- **含义**：
  - 第一项：$\frac{W}{P}$ 表示工作量被 $P$ 个处理器分摊后每个处理器的负担。
  - 第二项：$D$ 表示所有处理器必须经历的计算树深度。

### 2.2 WD-模式充分性定理
- 若一个算法在 WD 模式下表示为：  
  $O(W, D)$  
  则可以使用 $P$ 个处理器在以下时间内实现：  
  $$T = O\left(\frac{W}{P} + D\right)$$

---

## 3. 并行算法案例
### 3.1 前缀和问题（Prefix-Sum）
- **输入**：  
  $A(1), A(2), \dots, A(n)$  

- **输出**：  
  $\text{Prefix-Sum: } S_i = \sum_{j=1}^i A(j)$

- **公式**：
  - 树状求和：
    $$B(h, i) = B(h-1, 2i-1) + B(h-1, 2i)$$  
    其中 $h = 1, 2, \dots, \log n$，$i = 1, 2, \dots, n/2^h$。

  - 输出：
    $$S(i) = B(\log n, 1)$$

- **复杂度**：
  - 深度：
    $$D = O(\log n)$$
  - 工作量：
    $$W = O(n)$$

---

### 3.2 并行求和问题
- **公式**：
  - 输入：
    $A(1), A(2), \dots, A(n)$

  - 每一步递归：
    $$B(h, i) = B(h-1, 2i-1) + B(h-1, 2i)$$  
    其中 $h = 1, 2, \dots, \log n$，$i = 1, 2, \dots, n/2^h$。

  - 输出：
    $$\text{Sum} = B(\log n, 1)$$

- **复杂度**：
  - 深度：  
    $$D = O(\log n)$$
  - 工作量：  
    $$W = O(n)$$

---

### 3.3 最大值问题
- **公式**：
  - 替代求和中的加法为取最大值：  
    $$B(h, i) = \max\left(B(h-1, 2i-1), B(h-1, 2i)\right)$$

  - 输出：  
    $$\text{Max} = B(\log n, 1)$$

- **复杂度**：
  - 深度：  
    $$D = O(\log n)$$
  - 工作量：  
    $$W = O(n)$$

---

### 3.4 归并排序中的并行排名问题
- **定义**：  
  给定两个已排序数组 $A$ 和 $B$，将其合并为一个有序数组 $C$。

- **公式**：
  - 排名问题定义：
    $$\text{RANK}(j, A) = i \quad \text{若 } A(i) < B(j) < A(i+1)$$

  - 排名公式：
    $$C(i + \text{RANK}(i, B)) = A(i)$$  
    $$C(i + \text{RANK}(i, A)) = B(i)$$

- **复杂度**：
  - 排名：二分搜索：  
    $$O(\log n)$$
  - 合并工作量：  
    $$W = O(n+m)$$

---

## 4. 随机采样与概率分析
### 4.1 随机采样求最大值
- **算法过程**：
  1. 随机从输入 $A$ 中抽取 $B(n^{7/8})$ 个元素。
  2. 用 $B$ 估算 $A$ 的最大值 $M$。
  3. 若 $A$ 中仍存在大于 $M$ 的元素，重复抽样。

- **复杂度**：
  - 高概率下，深度：
    $$D = O(1)$$
  - 工作量：
    $$W = O(n)$$

- **概率优化**：
    若期望误差为 $\epsilon$，可以选择 $k$ 使得其**标准误差**满足：

    $$
    k = O\left(\frac{1}{\epsilon^2}\right)
    $$

### 4.2 （补充）问题：随机采样求最大值的并行算法

**随机采样求最大值的并行算法**是一种通过在给定数据中进行随机抽样，来估计数据的最大值的算法。该方法的核心思想是通过多次采样和并行处理，减少了求解最大值的计算量，并提高了处理效率，尤其适用于大规模数据集。

#### 问题背景

在处理大规模数据时，传统的寻找最大值的方法（遍历整个数据集）可能会非常慢，特别是数据量巨大的情况下。通过随机采样，可以大致估算出最大值，而不必遍历所有数据，这样能够大大提高效率。

#### 基本思想

1. **随机采样**：从数据集 $D$ 中随机选择一些样本元素。
2. **并行计算**：多个处理器并行地处理不同的随机样本，并在局部计算中找到最大值。
3. **合并结果**：最终，从多个局部结果中选择出全局最大值。

#### 算法步骤

假设我们有 $n$ 个元素的数据集 $D = \{d_1, d_2, \dots, d_n\}$，并且我们希望通过并行计算随机采样的方式来估算最大值。

1. 随机选择样本

随机从数据集 $D$ 中选择 $k$ 个元素作为样本：

$$
S = \{d_{i_1}, d_{i_2}, \dots, d_{i_k}\}
$$

其中 $i_1, i_2, \dots, i_k$ 是从 $\{1, 2, \dots, n\}$ 中随机选出的 $k$ 个索引。

2. 并行求局部最大值

将样本 $S$ 分配到 $p$ 个处理器，每个处理器计算一部分样本的最大值：

- 处理器 $T_1$ 计算样本中的最大值 $\text{max}_1$。
- 处理器 $T_2$ 计算样本中的最大值 $\text{max}_2$。
- ...
- 处理器 $T_p$ 计算样本中的最大值 $\text{max}_p$。

3. 合并局部最大值

所有 $p$ 个处理器计算完后，最终的最大值是这些局部最大值的最大值：

$$
\text{max}_\text{final} = \max(\text{max}_1, \text{max}_2, \dots, \text{max}_p)
$$

4. 输出结果

返回最终的最大值 $\text{max}_\text{final}$。

#### 时间复杂度

1. **随机采样**：随机选择 $k$ 个样本的操作通常是 $O(k)$。
2. **并行计算局部最大值**：将 $k$ 个样本分配给 $p$ 个处理器，每个处理器处理 $k/p$ 个元素。每个处理器计算最大值的时间复杂度为 $O(k/p)$，在 $p$ 个处理器上并行执行，总的时间复杂度为 $O(k/p)$。
3. **合并最大值**：合并 $p$ 个局部最大值的操作时间复杂度为 $O(p)$。

因此，**总的时间复杂度**是：

$$
O(k/p + p)
$$

其中：
- $k$ 是样本大小。
- $p$ 是并行处理器的数量。

#### 选择样本大小 $k$

为了使得估计的最大值接近真实最大值，可以利用概率论来选择适当的样本大小 $k$。

- **采样误差**：根据**大数法则**，如果 $k$ 足够大，采样的最大值 $\text{max}_S$ 期望值接近数据集的真实最大值 $\text{max}_D$。
- **概率保证**：选择适当的 $k$，可以使得通过随机采样得到的最大值与真实最大值之间的误差在某个容忍范围内。

##### 理论分析

如果我们从数据集 $D$ 中随机选择 $k$ 个元素，则有以下结论：
- 估计的最大值 $\text{max}_S$ 的期望值趋近于真实的最大值 $\text{max}_D$。
- 误差可以通过调整 $k$ 来控制。如果需要更高的精度，增大 $k$。

通常，若期望误差为 $\epsilon$，可以选择 $k$ 使得其**标准误差**满足：

$$
k = O\left(\frac{1}{\epsilon^2}\right)
$$

这意味着更高精度的估计需要更多的样本。

#### 优缺点

1. 优点：
    1. **提高效率**：通过并行化和随机采样，避免了对整个数据集的遍历，减少了计算量，特别适用于大规模数据集。
    2. **适用于分布式系统**：可以在分布式计算环境中使用，利用多个节点进行并行计算。
    3. **可控制精度**：通过调整样本大小 $k$ 来控制误差的大小，提供灵活性。

2. 缺点：
    1. **近似解**：这种方法得到的是**近似最大值**，而非确切的最大值。样本越小，结果的误差越大。
    2. **样本选择偏差**：如果数据分布不均匀，某些元素可能不会出现在采样中，从而影响结果的准确性。

#### 应用场景
1. **大规模数据处理**：例如在大数据环境下（如 MapReduce、Hadoop 或 Spark），随机采样可以大大提高数据处理效率。
2. **实时计算**：在实时计算中，使用随机采样可以快速获取近似的最大值，从而避免了全数据遍历的延迟。
3. **分布式系统**：在分布式计算环境中，多个节点可以并行进行随机采样和局部计算，最终合并结果。

通过随机采样求最大值的并行算法，能够在大数据集上有效提高效率，并且具有较好的扩展性，适用于大规模数据分析和分布式计算任务。

---

## 5. MapReduce 模型
### 5.1 MapReduce 框架公式
- **模型公式**：
  - **Map**：
    $$(\text{Key}, \text{Value}) \to (\text{Intermediate Key}, \text{Intermediate Value})$$
  - **Reduce**：
    $$(\text{Intermediate Key}, [\text{Intermediate Values}]) \to (\text{Key}, \text{Result})$$